![imgur](https://i.imgur.com/4O2X2RO.jpeg)
![imgur](https://i.imgur.com/EaKUhne.png)

# AI_CUP_STAS_I_995
è‚ºè…ºç™Œç—…ç†åˆ‡ç‰‡å½±åƒä¹‹è…«ç˜¤æ°£é“æ“´æ•£åµæ¸¬ç«¶è³½ Iï¼šé‹ç”¨ç‰©é«”åµæ¸¬ä½œæ³•æ–¼æ‰¾å°‹STAS
å ±å‘Šèªªæ˜æ–‡ä»¶
<h1>å£¹ã€	ç’°å¢ƒ</h1>
ã€€ã€€æˆ‘å€‘ä½¿ç”¨Windowsä½œæ¥­ç³»çµ±ä¾†é€²è¡Œé€™å€‹å°ˆæ¡ˆï¼Œä¸¦ä¸”ä»¥Pythoné–‹ç™¼ç’°å¢ƒï¼Œä½†é€™å€‹ç’°å¢ƒä¸è¦‹å¾—å¯ä»¥æ”¯æ´GPUåŠ é€Ÿè¨ˆç®—ï¼Œé›–èªªPytorchä¹Ÿæ˜¯æ”¯æ´CPUè¨ˆç®—ï¼Œä½†å–®ä½¿ç”¨CPUè¨ˆç®—æ™‚é–“æœƒéå¸¸ä¹…ï¼Œæ‰€ä»¥æˆ‘å€‘é‹ç”¨CPU Intel(R) Core(TM) i9-11900H @ 2.50GHzæ­é…GPU NVIDIA GEFORCE RTX 3080 RTXä¾†åŠ é€Ÿè¨ˆç®—ã€‚ä½¿ç”¨githubä¸Šultralytics æ‰€æä¾›Pytorch æ¡†æ¶çš„ yolov5ï¼Œæ˜¯ä¸€ç¨®åŸºæ–¼yolov4 : AlexexAB fork githubçš„ç›®æ¨™æª¢æ¸¬ç®—æ³•ã€‚

* ä½œæ¥­ç³»çµ±ï¼šWindows
* CPUï¼šIntel(R) Core(TM) i9-11900H @ 2.50GHz
* GPUï¼šNVIDIA GEFORCE RTX 3080 RTX
* èªè¨€ï¼šPython 3.8.10
* Torchï¼štorch 1.9.0ï¼‹cu111
* yolov5 : ultralytics fork github 
<h1>è²³ã€	æ¼”ç®—æ–¹æ³•èˆ‡æ¨¡å‹æ¶æ§‹</h1>
ã€€ã€€ä½¿ç”¨GITHUBä¸Šï¼Œultralyticsæ‰€æä¾›çš„yolov5ã€‚yolov5å®˜æ–¹ç¨‹å¼ç¢¼ä¸­ï¼Œçµ¦å‡ºçš„ç›®æ¨™æª¢æ¸¬ç¶²è·¯ä¸­ä¸€å…±æœ‰4å€‹ç‰ˆæœ¬ï¼Œåˆ†åˆ¥æ˜¯yolov5sã€yolov5mã€yolov5lã€yolov5xå››å€‹æ¨¡å‹ã€‚yolov5ç¨‹å¼ç¢¼ä¸­çµ¦å‡ºçš„ç¶²è·¯æª”æ¡ˆæ˜¯yamlæ ¼å¼æª”æ¡ˆï¼Œå’ŒåŸæœ¬yolov3ã€yolov4ä¸­çš„cfgæ ¼å¼æª”æ¡ˆä¸åŒã€‚yolov5ä½œè€…æ˜¯åœ¨COCOè³‡æ–™é›†ä¸Šé€²è¡Œçš„æ¸¬è©¦ï¼Œè€Œ COCOè³‡æ–™é›†çš„å°ç›®æ¨™ä½”æ¯”ï¼Œå› æ­¤æœ€çµ‚çš„å››ç¨®ç¶²è·¯çµæ§‹ï¼Œæ•ˆèƒ½ä¸Šä¾†èªªå„æœ‰åƒç§‹ã€‚yolov5sç¶²è·¯è¤‡é›œåº¦æœ€å°ï¼Œé€Ÿåº¦æœ€å¿«ï¼ŒAPç²¾åº¦ä¹Ÿæœ€ä½ã€‚å…¶ä»–çš„ä¸‰ç¨®ç¶²è·¯ï¼Œåœ¨æ­¤åŸºç¤ä¸Šï¼Œä¸æ–·åŠ æ·±åŠ å¯¬ç¶²è·¯ï¼ŒAPç²¾åº¦ä¹Ÿä¸æ–·æå‡ï¼Œä½†é€Ÿåº¦çš„æ¶ˆè€—ä¹Ÿåœ¨ä¸æ–·å¢åŠ ã€‚åœ–ä¸€æ˜¯yolov5ä½œè€…çš„æ¼”ç®—æ³•æ•ˆèƒ½æ¸¬è©¦åœ–ï¼Œè¡¨ä¸€æ˜¯é è¨“ç·´çš„æª¢æŸ¥é»ï¼Œæ‰€æœ‰æª¢æŸ¥é»éƒ½ä½¿ç”¨é è¨­è¨­ç½®è¨“ç·´åˆ° 300 å€‹ epochã€‚

* Nano å’Œ Small æ¨¡å‹ä½¿ç”¨hyp.scratch-low.yaml hypsï¼Œæ‰€æœ‰å…¶ä»–æ¨¡å‹ä½¿ç”¨hyp.scratch-high.yamlã€‚mAP valå€¼é©ç”¨æ–¼COCO val2017æ•¸æ“šé›†ä¸Šçš„å–®æ¨¡å‹å–®å°ºåº¦ã€‚
```python val.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65```

* TTA æ¸¬è©¦æ™‚é–“å¢å¼·åŒ…æ‹¬åå°„å’Œæ¯”ä¾‹å¢å¼·ã€‚
```python val.py --data coco.yaml --img 1536 --iou 0.7 --augment```

![Imgur](https://i.imgur.com/kI9Vu4F.png "yolov5ä½œè€…çš„æ¼”ç®—æ³•æ•ˆèƒ½æ¸¬è©¦åœ–")[1]
![Imgur](https://i.imgur.com/ugNm0x5.png "é è¨“ç·´çš„æª¢æŸ¥é»")[1]

* ç¶²å€ï¼šhttps://github.com/ultralytics/Yolov5/releases
* ä½¿ç”¨æ¨¡å‹åŒ…æ‹¬ï¼šYOLOv5nã€YOLOv5sã€YOLOv5mã€YOLOv5lã€YOLOv5xã€YOLOv5n6ã€YOLOv5s6ã€YOLOv5m6ã€YOLOv5l6ã€YOLOv5x6+ TTAã€‚
<h1>åƒã€	è³‡æ–™è™•ç†</h1>
è³‡æ–™é è™•ç†éƒ¨åˆ†ï¼Œä¸»è¦åšä¸‰å€‹å‹•ä½œã€‚
åˆ©ç”¨ä¸»è¾¦å–®ä½æ‰€æä¾›çš„å£“ç¸®æª”(OBJ_Train_Datasets.zip)è³‡è¨Šï¼Œå…¶ä¸­å…§å®¹åˆ†åˆ¥æœ‰Train_Annotationsã€Train_Imageså…©å€‹è³‡æ–™å¤¾ï¼Œå…§å«1053å¼µåœ–ç‰‡(jpg)ä»¥åŠ1053å€‹æ¨™è¨˜æª”(xml)ã€‚

* æ­¥é©Ÿä¸€ï¼šæ¡ç”¨éš¨æ©Ÿåˆ†é…å›ºå®šæ¯”ä¾‹æ–¹å¼åˆ†æˆ8æ¯”2ï¼Œè¨“ç·´é›†842ç­†å’Œæ¸¬è©¦é›†131ç­†ã€‚é™„æª”æª”åï¼šStep_1_data_split.py
```
# data split
import numpy as np
import shutil
import os

from_img_dir = './OBJ_Train_Datasets/Train_Images/'
from_xml_dir = './OBJ_Train_Datasets/Train_Annotations/'
img_list = os.listdir(from_img_dir)
print('Files include ',img_list[:4])
n_img = len(img_list)
print('Number of Images =', n_img)

np.random.shuffle(img_list)
print('After shuffling, files became', img_list[:4])

# data split for training and testing set
split_ratio = 0.2 # Train:Val = 8:2
n_train = round(n_img*(1-split_ratio))
n_val = n_img - n_train

train_list = img_list[:n_train]
val_list = img_list[n_train:]

# data redistribution
dataset_dir = './datasets/'
os.mkdir(dataset_dir)
train_dir = dataset_dir + 'train/'
os.mkdir(train_dir)
train_img_dir = train_dir + 'images/'
os.mkdir(train_img_dir)
train_xml_dir = train_dir + 'xml/'
os.mkdir(train_xml_dir)
val_dir = dataset_dir + 'val/'
os.mkdir(val_dir)
val_img_dir = val_dir + 'images/'
os.mkdir(val_img_dir)
val_xml_dir = val_dir + 'xml/'
os.mkdir(val_xml_dir)

# for training set
for file_name in train_list:
   # for images
   from_file = from_img_dir + file_name
   print("0",from_file)
   to_file = train_img_dir + file_name
   print("1",to_file)
    hutil.copy(from_file, to_file)
    # for xml
    xml_name = file_name[:-4] + '.xml'
    from_file = from_xml_dir + xml_name
    to_file = train_xml_dir + xml_name
    print("2",to_file)
    print("3",from_file)
    shutil.copy(from_file, to_file)
    
# for validation set
for file_name in val_list:
   # for images
   from_file = from_img_dir + file_name
   to_file = val_img_dir + file_name
   shutil.copy(from_file, to_file)
   # for xml
   xml_name = file_name[:-4] + '.xml'
   from_file = from_xml_dir + xml_name
   to_file = val_xml_dir + xml_name
shutil.copy(from_file, to_file) 
```

* æ­¥é©ŸäºŒï¼šæª¢æŸ¥xmlæª”ã€‚é™„æª”æª”åï¼šStep_2_xml_check.py
```
# xml2txt
import numpy as np
from lxml import etree
import os

def xml_label_check(xml_path):
    tree = etree.parse(xml_path)
    root = tree.getroot()
    label_list = []
    for obj in root.findall('object'):
        #print(obj.find('name').text)
        label_list.append(obj.find('name').text)
    label_set = list(set(label_list))
    return label_set

# main
xml_dir = './OBJ_Train_Datasets/Train_Annotations/'
label_collection = []
for xml_file in os.listdir(xml_dir):
    label_set = xml_label_check(xml_dir+xml_file)
    label_collection.extend(label_set)
label_collection = list(set(label_collection)) 
print(label_collection)
```

* æ­¥é©Ÿä¸‰ï¼šxmlæª”è½‰æˆç¨‹å¼æ‰€éœ€çš„txtæª”ã€‚é™„æª”æª”åï¼šStep_3_xml2txt.py
```
# xml2txt
import numpy as np
from lxml import etree
import cv2
import os

def xml2txt(from_xml_path, to_txt_path):
  tree = etree.parse(xml_path)
  root = tree.getroot()
  width = int(root.find('size').find('width').text)
  height = int(root.find('size').find('height').text)

    label_list = []
    for obj in root.findall('object'):
        #print(obj.find('name').text)
        label_list.append(obj.find('name').text)
        for bbox in obj.findall('bndbox'):
            # bb = [xmin, ymin, xmax, ymax]
            bb = []
            for pts in bbox.getchildren():
                bb.append(int(pts.text))
    label_set = list(set(label_list))
    return label_set

# main
mode = 'train'
img_dir = './datasets/' + mode + '/images/'
xml_dir = './datasets/' + mode + '/xml/'
gt_dir = './datasets/' + mode + '/gt_img/'
if(not os.path.exists(gt_dir)):
    os.mkdir(gt_dir)
txt_dir = './datasets/' + mode + '/labels/'
if(not os.path.exists(txt_dir)):
    os.mkdir(txt_dir)

label_dict = {'Background':0, 'stas':1, 'STAS':1 }
color_dict = {'Background':(0,0,0), 'stas':(0,255,255), 'STAS':(0,255,255) }

img_list = os.listdir(img_dir)
xml_list = os.listdir(xml_dir)
n_file = len(xml_list)
for i in range(n_file):
    xml_name = xml_list[i]
    img_name = img_list[i]
    img = cv2.imread(img_dir+img_name)
    # xml sparse
    tree = etree.parse(xml_dir+xml_name)
    root = tree.getroot()
    width = int(root.find('size').find('width').text)
    height = int(root.find('size').find('height').text)
    # go through every region
    txt_info = []
    for obj in root.findall('object'):
        label_name = obj.find('name').text
        for bbox in obj.findall('bndbox'):
            # bb = [xmin, ymin, xmax, ymax]
            bb = []
            for pts in bbox.getchildren():
                bb.append(int(pts.text))
        pt1 = (bb[0],bb[1]) # top-left corner
        pt2 = (bb[2],bb[3]) # bottom-right corner
        color_set = color_dict[label_name]
        # draw bbox
        cv2.rectangle(img,pt1,pt2,color_set,2)
        # yolo txt : [label_num, xc, yc, w, h]
        label_num = label_dict[label_name]
        xc = ((bb[0]+bb[2])/2)/width
        yc = ((bb[1]+bb[3])/2)/height
        w = (bb[2]-bb[0])/width
        h = (bb[3]-bb[1])/height
        txt_info.append([label_num, xc, yc, w, h])
    txt_np = np.array(txt_info)
    txt_name = xml_name[:-4] + '.txt'
    np.savetxt(txt_dir+txt_name, txt_np, fmt='%1.3f', delimiter =' ')
    cv2.imwrite(gt_dir+img_name, img)
```


<h1>è‚†ã€	è¨“ç·´æ–¹å¼</h1>

ã€€ã€€ç”¨éš¨æ©Ÿåˆ†é…å›ºå®šæ¯”ä¾‹æ–¹å¼åˆ†æˆ8æ¯”2ï¼Œè¨“ç·´é›†842ç­†å’Œæ¸¬è©¦é›†131ç­†ã€‚ä»¥è¡¨ä¸€æ¬Šé‡æª”åšç‚ºåŸºåº•ï¼Œå†åŠ ä¸Šæ–°çš„è³‡æ–™ç¹¼çºŒåšè¨“ç·´ï¼ŒæœŸä»¥èƒ½å¤ æé«˜æº–ç¢ºç‡ã€‚æˆ‘å€‘ç”¨ä¸Šè¿°çš„è¨“ç·´æ–¹å¼é‡è¤‡è¨“ç·´ï¼Œæœ‰å¾®èª¿æ¨¡å‹æ¶æ§‹è£¡çš„è¶…åƒæ•¸ï¼Œè¨“ç·´è¶…åƒæ•¸åŒ…æ‹¬ï¼šyamlæ–‡ä»¶çš„é¸æ“‡ï¼Œå’Œè¨“ç·´åœ–ç‰‡çš„å¤§å°ã€é è¨“ç·´ã€batchã€epochç­‰ã€‚å¯ä»¥ç›´æ¥åœ¨train.pyçš„parserä¸­ä¿®æ”¹ï¼Œä¹Ÿå¯ä»¥åœ¨å‘½ä»¤è¡ŒåŸ·è¡Œæ™‚ä¿®æ”¹ï¼Œå¦‚ä¸‹ï¼š[2]

```$ python train.py --data coco.yaml --cfg yolov5s.yaml --weights '' --batch-size 64```

* --dataæŒ‡å®šè¨“ç·´æ•¸æ“šæ–‡ä»¶
* --cfgè¨­ç½®ç¶²çµ¡çµæ§‹çš„é…ç½®æ–‡ä»¶
* --weightsåŠ è¼‰é è¨“ç·´æ¨¡å‹çš„è·¯å¾‘
* yamlæ–‡ä»¶ï¼š

```
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
# Hyperparameters for Objects365 training
# python train.py --weights yolov5m.pt --data Objects365.yaml --evolve
# See Hyperparameter Evolution tutorial for details https://github.com/ultralytics/yolov5#tutorials
lr0: 0.00258
lrf: 0.17
momentum: 0.779
weight_decay: 0.00058
warmup_epochs: 1.33
warmup_momentum: 0.86
warmup_bias_lr: 0.0711
box: 0.0539
cls: 0.299
cls_pw: 0.825
obj: 0.632
obj_pw: 1.0
iou_t: 0.2
anchor_t: 3.44
anchors: 3.2
fl_gamma: 0.0
hsv_h: 0.0188
hsv_s: 0.704
hsv_v: 0.36
degrees: 180.0 
translate: 0.0902
scale: 0.491
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
```

<h1>ä¼ã€	åˆ†æèˆ‡çµè«–</h1>

![Imgur](https://i.imgur.com/Ocs8Yn5.png "è¨“ç·´éç¨‹")

<h1>é™¸ã€	é›²ç«¯ä½¿ç”¨</h1>
 
ã€€ã€€æ¯”è³½æœŸé–“çš„Publicæˆç¸¾ï¼Œå‰›å¥½å¾ˆå¹¸é‹åœ¨æ’åç¬¬11åï¼Œæ“æœ‰å°æ™ºé›²å°‡æä¾›å‰30åçš„éšŠä¼æ–¼5/26~6/1å…±7å¤©ç­‰å€¼æ–°å°å¹£3è¬é¡åº¦çš„TWCCé›²ç«¯é‹ç®—è³‡æºä½¿ç”¨æ¬Šé™ï¼Œæ›ç®—å¯è®“æ¯å€‹éšŠä¼å¯ä»¥ä½¿ç”¨ä¸€å¼µNVIDIAÂ® Tesla V100 GPUç´„490å€‹å°æ™‚ä¹‹é›²ç«¯è³‡æºã€‚
ã€€ã€€é‹ç”¨TWCCé›²ç«¯é‹ç®—è³‡æºçš„å®¹å™¨é‹ç®—æœå‹™ (Container Compute Service, CCS)ï¼Œä»–çš„æœå‹™é …ç›®åŒ…å«é–‹ç™¼å‹å®¹å™¨ã€ä»»å‹™å‹å®¹å™¨ã€‚é…å‚™ 8 å€‹ NVIDIAÂ® Tesla V100 GPUï¼ŒåŠ é€Ÿäººå·¥æ™ºæ…§è¨“ç·´ã€æ¨è«–èˆ‡é«˜æ•ˆèƒ½é‹ç®—ï¼Œæ”¯æ´ 5120 å€‹ CUDA æ ¸å¿ƒèˆ‡ 640 å€‹ Tensor æ ¸å¿ƒï¼Œä¸¦æ”¯æ´ NVLink é€²è¡Œ GPU ä¹‹é–“çš„è³‡æ–™å‚³è¼¸ï¼ŒåŠ é€Ÿäººå·¥æ™ºæ…§è¨“ç·´ã€æ¨è«–èˆ‡é«˜æ•ˆèƒ½é‹ç®—ã€‚[3]

![Imgur](https://i.imgur.com/nYfJdfu.png "ç«¶è³½èªªæ˜")

æˆ‘å€‘ä½¿ç”¨å®¹å™¨å‹è™Ÿc.4xsuperé€²è¡Œé‹ç®—ï¼Œæ¯”è¼ƒä½¿ç”¨æœ¬æ©Ÿç«¯CPU Intel(R) Core(TM) i9-11900H @ 2.50GHzæ­é…GPU NVIDIA GEFORCE RTX 3080 RTXï¼Œè¨“ç·´æ™‚é•·å·®è·ä¸‰å€ã€‚
<h1>æŸ’ã€	ç¨‹å¼ç¢¼</h1>
æˆ‘å€‘å°‡ç¨‹å¼ä¸Šæ¶åˆ°GITHUBä¸Šï¼Œ

* ç¶²å€ï¼šhttps://github.com/SmallliDinosaur/AI_CUP_STAS_I_995

1.	å‰è™•ç†ç¨‹å¼ç¢¼ã€‚
* ç¶²å€ï¼šhttps://github.com/SmallliDinosaur/AI_CUP_STAS_I_995/tree/main/Before
2.	è¨“ç·´ç¨‹å¼ç¢¼ã€‚
3. è¢«è¨“ç·´å¥½çš„æ¨¡å‹æª”æ¡ˆ(æ¨¡å‹æ¬Šé‡æª”, ä¾‹å¦‚.matæ ¼å¼)ã€‚
4. è¾¨è­˜ç¨‹å¼ç¢¼(åŒ…å«ä¸Šå‚³ç«¶è³½ç¶²é ä¹‹é æ¸¬çµæœè¼¸å‡º)ã€‚
5. å„é …åƒæ•¸ä¹‹è¨­å®šã€‚
6. åŸ·è¡Œç’°å¢ƒ(æ‰€ä½¿ç”¨çš„ç¨‹å¼ç‰ˆæœ¬(tensorflow/keras/pyrotch/matlab)èˆ‡é–‹ç™¼æ‰€éœ€çš„é¡å¤–Support packageç‰ˆæœ¬)ã€‚


<h1>æŒã€	ä½¿ç”¨çš„å¤–éƒ¨è³‡æºèˆ‡åƒè€ƒæ–‡ç»</h1>
[1]	ultralytics(2022, February 2). Yolov5x6.pt, Pretrained Checkpoints,Retrieved from https://github.com/ultralytics/Yolov5/releases

[2]	Laughing-q (2020, July 20). YOLOV5è¨“ç·´ä»£ç¢¼train.pyè¨»é‡‹èˆ‡è§£æ, Retrieved from https://blog.csdn.net/Q1u1NG/article/details/107463417

[3]	TWS (2022). CCS å®¹å™¨é‹ç®—æœå‹™, Retrieved from https://tws.twcc.ai/service/container-compute-service/



 
<h1>è¯çµ¡è³‡æ–™</h1>

éšŠä¼

* éšŠä¼åç¨±	Team 995

éšŠå“¡

* é™³å† éœ–(Guan-Lin Chen)
* å³è²å„€(Chen-Yi Wu)

æŒ‡å°æ•™æˆ

* å¾ä½æ–‡


